// markov chain path guiding:
// Lucas Alber, Johannes Hanika, and Carsten Dachsbacher.
// Real-time Markov chain path guiding for global illumination and single scattering.
// Proc. ACM Comput. Graph. Interact. Tech., 8(1), 2025. 
#version 460
#extension GL_GOOGLE_include_directive              : enable
#extension GL_EXT_ray_tracing                       : enable
#extension GL_EXT_ray_query                         : enable
#extension GL_EXT_ray_tracing_position_fetch        : enable
#extension GL_EXT_shader_explicit_arithmetic_types  : enable
#extension GL_EXT_nonuniform_qualifier              : enable
#extension GL_EXT_control_flow_attributes           : enable
#extension GL_KHR_shader_subgroup_ballot            : enable
#extension GL_KHR_shader_subgroup_arithmetic        : enable
#extension GL_EXT_scalar_block_layout               : enable
#extension GL_EXT_shader_atomic_float               : enable

#define MAX_PATH_LENGTH 2
#define MC_SAMPLES 5
#define MC_SAMPLES_ADAPTIVE_PROB 0.7
#define SURFACE_SPP 2

#include "shared.glsl"
#include "shared/render3d.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

layout(std140, set = 0, binding = 0) uniform global_t
{ 
  int frame;
} global;

layout(std140, set = 0, binding = 1) uniform params_t
{ 
  vec4 cam_x;
  vec4 cam_w;
  vec4 cam_u;
  vec4 fog;
  float cltime;
  int spp;
} params;

#include "config.h"

layout(set = 1, binding = 0) buffer buf_fb_t { float v[]; } buf_fb;
layout(set = 1, binding = 1) uniform sampler2D img_blue;
layout(set = 1, binding = 2) uniform sampler2D img_tex[];
layout(set = 1, binding = 3) uniform writeonly image2D img_aov;
layout(set = 1, binding = 4) uniform sampler2D img_env;
layout(set = 1, binding = 5) uniform sampler2D img_dn;
layout(set = 1, binding = 6) buffer buf_mat_t { gbuf_t v[]; } buf_mat; // material+st
layout(set = 2, binding = 0) uniform accelerationStructureEXT rt_accel;
layout(set = 2, binding = 1) buffer buf_vtx_t { rtgeo_vtx_t v[]; } buf_vtx[];

#include "shared/fb.glsl" // depends on buf_fb
#include "raytrace.glsl"  // depends on rt_accel and buf_vtx
#include "env.glsl"
#include "colour.glsl"
#include "volume-fwd.glsl"
#include "volume.glsl"
#include "complex.glsl"
#include "fresnel.glsl"
#include "material.glsl"  // depends on img_tex
#include "camera-fwd.glsl"
#include "camera.glsl"

// Algorithm "xor" from p. 4 of Marsaglia, "Xorshift RNGs"
// Returns random float in [0, 1) and updates state.

float XorShift32(inout uint state) {
    state ^= state << 13;
    state ^= state >> 17;
    state ^= state << 5;
    return state / 4294967296.0;
}

#define XorShift32Vec2(state) vec2(XorShift32(state), XorShift32(state))
#define XorShift32Vec3(state) vec3(XorShift32(state), XorShift32(state), XorShift32(state))
#define XorShift32Vec4(state) vec4(XorShift32(state), XorShift32(state), XorShift32(state), XorShift32(state))

vec4 dithermask(vec4 xi, ivec2 rp)
{
  return fract(xi + texelFetch(img_blue, rp, 0));
}

#include "grid.glsl"
#include "hash.glsl"

layout(set = 0, binding = 16, scalar) buffer restrict buf_mc_states {
    MCState mc_states[];
};
layout(set = 0, binding = 17, scalar) buffer restrict buf_light_cache {
    LightCacheVertex light_cache[];
};
layout(set = 0, binding = 18, scalar) buffer restrict buf_dist_mc_states {
    DistanceMCVertex distance_mc_states[];
};

uint rng_state;
vec2 moments;
vec3 irr;

#include "light_cache.glsl"
#include "mc.glsl"

// XXX todo: maybe we want a special gbuf pass to compute directly that, so we don't have to fill it again from our gbuf structs?
// XXX we have: mat_state_t (ns, sampled colours+roughness), gbuf_t (ng, st, mat uints straight outta rt), dn buf (depth + ns)
// XXX how would we access prev pos? needs support in prepare_intersection and buf_vtx_prev. dn buf should have prev pos.
// TODO this one here is used for the ray tracing interface in merian. replace by our interface and carry on?
struct Hit {
    vec3 pos;
    vec3 prev_pos;
    vec3 wi;
    vec3 normal;
    uint enc_geonormal;

    // Material
    f16vec3 albedo;
    float16_t roughness;
};
#define pixel ivec2(gl_GlobalInvocationID)
#define resolution ivec2(imageSize(img_irradiance))
#define first_hit hits[gbuffer_index(pixel, resolution)]

// XXX new main:
// vec4 // returns rgb L + second moment of luminance
// pt_trace(
//     ivec2 ipos,      // pixel coordinate
//     uint  seed,      // random seed
//     ivec2 fbdim,     // frame buffer dimensions
//     out vec3 albedo) // return base texture on first hit as aov for denoiser
// TODO trace up to geo intersection only! volumes will be a separate pass
void main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  ivec2 fbdim = ivec2(imageSize(img_aov));
  uint seed = 19937 * global.frame + 133700000 * ipos.x + ipos.y * 70007;
  // blue noise dither mask
  const ivec2 rp = ivec2(ipos % ivec2(textureSize(img_blue, 0)));

  camera = camera_t(0.5, vec2(1.0, fbdim.y/float(fbdim.x)), params.cam_x.xyz, mat3(1));
  camera_setup(params.cam_x.xyz, params.cam_w.xyz, params.cam_u.xyz);

  uint vidx = -1u;    // vertex index in path cache that we stored last iteration
  vec4 acc = vec4(0); // value of our estimator, accumulate this
  vec4 hrp = vec4(1); // hero wavelength p, only deviates from 1 if pdf is different per wavelength
  vec4 rand = XorShift32Vec4(seed);
  vec4 contrib = vec4(1.0);
  // dithermask shows *no* difference for stratified hwl:
  uint seed2 = 19937*global.frame;
  vec4 lambda = colour_sample_lambda(dithermask(vec4(XorShift32(seed2)), rp), contrib, hrp);

  vec4 x;
  vec3 w, n, ng; // ray position, direction, hit normal
  vec2 st;       // texture coordinates
  uvec3 mat;
  contrib *= camera_sample_xw((ipos+filter_bh_sample(rand.yz))/fbdim, x, w);
  // contrib *= camera_sample_xw(vec2(ipos)/fbdim, x, w);
  int act = mix(1, 0, all(lessThanEqual(contrib, vec4(0.0))));

  uint flags = 0;
  float dist = 1e20;
  const float tmax = 1e12;//volume_sample_dist(x.xyz, w, mrand(seed));

  { // init first intersection vertex: read geo intersection info
    vec2 dn = texelFetch(img_dn, ipos, 0).rg;
    dist = dn.x;
    n  = geo_decode_normal(floatBitsToUint(dn.y));
    ng = geo_decode_normal(buf_mat.v[ipos.x+fbdim.x*ipos.y].ng);
    mat = uvec3(
        buf_mat.v[ipos.x+fbdim.x*ipos.y].m0,
        buf_mat.v[ipos.x+fbdim.x*ipos.y].m1,
        buf_mat.v[ipos.x+fbdim.x*ipos.y].m2);
    uint stui = buf_mat.v[ipos.x+fbdim.x*ipos.y].st;
    if(stui == -1u) n = vec3(0);
    st = unpackUnorm2x16(stui);
    if(dist < tmax) flags = 0;
    else          { flags = s_volume; dist = tmax; }
    if(dist >=1e10) flags = s_envmap;
    x.xyz = x.xyz + dist * w + 0.001*ng;
  }

  if ((flags & s_envmap) == 0) for (int s = 0; s < SURFACE_SPP; s++)
  {
  for(int bounce=0;bounce<MAX_PATH_LENGTH;bounce++)
  { // for a max number of path segments (every iteration traces one ray in addition to the eye ray)
    mat_state_t ms;
    if(act > 0)
    {
      vec3 albedo;
      ms = mat_init(mat, st, n, flags, lambda, w, albedo);
      // TODO write albedo to buffer for svgf

      if((flags & s_emit) != 0)
        acc += contrib * ms.col_emit;
    }

    act = mix(act, 0, all(lessThanEqual(contrib, vec4(0.0)))); // contribution dropped
    act = mix(act, 0, (flags & (s_emit|s_envmap)) > 0); // endpoint found
    if(subgroupAdd(act) <= 0) break; // keep subgroup in sync

    if(act > 0)
    { // SAMPLE NEXT OUTGOING DIRECTION
      vec3 wo;
      float wodotn;
      float wo_p = 0;

#if MCPG_REFERENCE_MODE==1
      rand = vec4(mrand(seed), mrand(seed), mrand(seed), mrand(seed));
      w = mat_sample(ms, flags, w, n, lambda, rand.xyz, contrib);
      if(dot(ng, w) <= 0) act = 0;
#else
      MCState mc_state;
      uint mc_buffer_index;

      float score_sum = 0;
      {
        float scores[MC_SAMPLES];
        vec4 vmfs[MC_SAMPLES];
        {
          [[unroll]] for (int i = 0; i < MC_SAMPLES; i++)
          {
            const bool adaptive_grid = XorShift32(rng_state) < MC_SAMPLES_ADAPTIVE_PROB;

            uint buffer_index, hash;
            if (adaptive_grid)
              mc_adaptive_buffer_index(s == 0 ? current_hit.prev_pos : current_hit.pos, current_hit.normal, buffer_index, hash);
            else
              mc_static_buffer_index(s == 0 ? current_hit.prev_pos : current_hit.pos, buffer_index, hash);

            MCState state = mc_states[buffer_index];

            if (adaptive_grid)
              mc_adaptive_finalize_load(state, hash);
            else
              mc_static_finalize_load(state, hash, current_hit.pos, current_hit.normal);

            scores[i] = state.sum_w;
            score_sum += state.sum_w;
            vmfs[i] = mc_state_get_vmf(state, current_hit.pos);
            if (XorShift32(rng_state) < scores[i] / score_sum)
            {
              // we use here that comparison with NaN is false, that happens if candidate_score == 0 and sum == 0; 
              mc_state = state;
              mc_buffer_index = buffer_index;
              wo = vmf_sample(vmfs[i].xyz, vmfs[i].w, XorShift32Vec2(rng_state));
            }
          }
        }

        if (score_sum == 0 || XorShift32(rng_state) < SURF_BSDF_P)
        {
          // BSDF Sampling
          wo = bsdf_ggx_diffuse_mix_sample(current_hit.wi, current_hit.normal, bsdf_ggx_roughness_to_alpha(current_hit.roughness), XorShift32Vec3(rng_state));
          mc_state = mc_state_new();
        } // else {VMF Sampling // wo = set above }
      wodotn = dot(wo, current_hit.normal);

      // ray is below geometric surface
      if (wodotn <= 1e-3 || dot(wo, geo_decode_normal(current_hit.enc_geonormal)) <= 1e-3)
        break;

      // Multiple importance sampling
      [[unroll]] for (int i = 0; i < MC_SAMPLES; i++)
      {
        // score_sum > 0 ? results in black artifacts
        wo_p += (scores[i] > 0 ? scores[i] * (vmf_pdf(wo, vmfs[i].xyz, vmfs[i].w)) / score_sum : 0);
      }
      wo_p = (score_sum > 0 ? SURF_BSDF_P : 1.0) *
        // XXX our material pdf here
        bsdf_ggx_diffuse_mix_pdf(current_hit.wi, wo, current_hit.normal, bsdf_ggx_roughness_to_alpha(current_hit.roughness)) + (1 - SURF_BSDF_P) * wo_p;

      }
#endif
    }

    dist = tmax; // trace ray
    if(cast_ray(w, x.xyz, dist, n, ng, st, mat)) flags = 0;
    else if(dist < tmax) flags = s_volume;
    if(dist >= 1e10)     flags = s_envmap;

    // TODO
    // Full GI (infinite diffuse bounces)
    const f16vec3 lc_incident = any(greaterThan(incident, f16vec3(0))) ||
      (USE_LIGHT_CACHE_TAIL == 0 && MAX_PATH_LENGTH == 2) ? incident :
      throughput * light_cache_get(next_hit.pos, next_hit.normal).rgb;

    // EVAL BSDF
    // without albedo (added below to skip first albedo)
    // TODO use our mat model
      const float microfacet_bsdf = bsdf_ggx_diffuse_mix_times_wodotn(current_hit.wi, wo, current_hit.normal, bsdf_ggx_roughness_to_alpha(current_hit.roughness), 0.02);

      current_throughput *= microfacet_bsdf;
      f = current_throughput * (bounce < MAX_PATH_LENGTH - 1 ? incident : lc_incident);
      p *= wo_p;
      current_throughput *= throughput;

      { // UPDATE MARKOV CHAIN and LIGHT_CACHE
        // multiply albedo?
        const float mc_f = luminance_rec2020(lc_incident * microfacet_bsdf / wo_p);
        if (!isinf(mc_f) && !isnan(mc_f))
        {
          light_cache_update(current_hit.pos, current_hit.normal, lc_incident * bsdf_diffuse_eval(current_hit.albedo) * wodotn / max(wo_p, 10));

          if (XorShift32(rng_state) * score_sum < mc_f * MC_SAMPLES)
          {
            // == XorShift32(rng_state) < mc_f / (score_sum / MC_SAMPLES)
            mc_state_add_sample(mc_state, current_hit.pos, mc_f, next_hit.pos, (next_hit.pos - next_hit.prev_pos) / TIME_DIFF);
            mc_static_save(mc_state, current_hit.pos, current_hit.normal);
            mc_adaptive_save(mc_state, current_hit.pos, current_hit.normal);
          }
          else if (MC_FAST_RECOVERY == 1 && mc_light_missing(mc_state, mc_f, wo, current_hit.pos))
          {
            // fix slow recovery after light source disappears
            mc_states[mc_buffer_index].sum_w = 0.;
          }
        }
      }

      // XXX i think we want to be doing this above when evaluating the material
        // current_throughput *= next_hit.albedo;
        // current_hit = next_hit;

    act = mix(act, 0, all(lessThanEqual(contrib, vec4(0.0)))); // contribution dropped
    if(subgroupAdd(act) <= 0) break; // keep subgroup in sync
    }

    const vec3 contrib = f / p;
    if(!any(isinf(contrib)) && !any(isnan(contrib)))
    {
      irr += contrib;
      const float l = luminance_rec2020(contrib);
      moments += vec2(l, l * l);
    }
  }

  if (any(greaterThanEqual(pixel, resolution)))
    return;

  if (SURFACE_SPP > 0)
    acc /= SURFACE_SPP;

  if(any(greaterThanEqual(ipos, fbdim))) return;

  vec3 acc_rgb;
  acc_rgb = colour_to_rgb(acc, lambda, hrp);
  fb_set(ipos, fbdim, vec4(acc_rgb, merian_square(luminance_rec2020(acc_rgb))));
}
