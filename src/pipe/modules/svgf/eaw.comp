#version 460
#extension GL_GOOGLE_include_directive    : enable

#include "shared.glsl"
#include "shared/render3d.glsl"

layout(local_size_x = DT_LOCAL_SIZE_X, local_size_y = DT_LOCAL_SIZE_Y, local_size_z = 1) in;

// layout(std140, set = 0, binding = 1) uniform params_t
// { } params;
layout(push_constant, std140) uniform push_t
{
  int gap;
} push;

layout(set = 1, binding = 0) uniform sampler2D img_irr;
layout(set = 1, binding = 1) uniform sampler2D img_gbuf;
layout(set = 1, binding = 2) uniform writeonly image2D img_out;
layout(set = 1, binding = 3) uniform writeonly image2D img_gbuf_out;

// christoph's vanilla svgf edge stopping functions:
float edge(
    vec2  dx,      // delta in screen space
    float s2,      // noise variance estimation for light
    vec3  Lp,      // center pixel light
    vec3  Lq,      // other pixel light
    vec3  np,      // normal center
    vec3  nq,      // normal other
    float dp,      // depth center
    float dq)      // depth other
{ // parameters from paper, default/paper version in comment:
  const float sigma_z = 8;     // parameter for depth      = 1   larger blurs more
  const float sigma_n = 32;    // parameter for normals    = 128 larger blurs more
  const float sigma_l = 64*pow(0.125,push.gap) * 2;     // parameter for brightness = 4   larger blurs more
  float w_z = exp(-abs(dp-dq) / (sigma_z));// * (1e-6+abs(dot(grad_z, dx)))));
  float w_n = pow(max(0.0, dot(np, nq)), sigma_n);
  float w_l = exp(-dot(abs(Lp-Lq), vec3(1))*sqrt(max(0,s2))/(sigma_l * sigma_l + 1e-6));
  return w_z * w_n * w_l;
}

void
main()
{
  ivec2 ipos = ivec2(gl_GlobalInvocationID);
  if(any(greaterThanEqual(ipos, imageSize(img_out)))) return;

  ivec2 sz = textureSize(img_irr, 0).xy;

  vec4  gbuf   = texelFetch(img_gbuf, ipos, 0);
  vec3  normal = geo_decode_normal(floatBitsToUint(gbuf.y));
  float depth  = gbuf.x;

  vec4 Lp = texelFetch(img_irr, ipos, 0);
  float m1 = luminance_rec2020(Lp.rgb);

  // if(false)
  if(push.gap == 1)
  { // spatially estimate 2nd moment
    float m2 = Lp.w;
    const int r = 1;
    for(int j=-r;j<=r;j++) for(int i=-r;i<=r;i++) if(i != 0 || j != 0)
    {
      vec4 irr = texelFetch(img_irr, ipos+ivec2(i,j), 0);
      float lum = luminance_rec2020(irr.rgb);
      m1 += lum;
      m2 += irr.w;
    }
    m1 /= (2.0*r+1)*(2.0*r+1);
    m2 /= (2.0*r+1)*(2.0*r+1);
    Lp.w = m2;
  }

  float w_sum = 1.0;
  vec4 res = w_sum * Lp;
  // evaluate filter:
#define FILTER \
    do {\
    vec4 tx = texture(img_irr, (ipos+ivec2(i,j)+0.5)/textureSize(img_irr, 0));\
    vec3 Lq = tx.rgb;\
    vec2 gbufq = texelFetch(img_gbuf, ipos+ivec2(i,j), 0).xy;\
    vec3 nq = geo_decode_normal(floatBitsToUint(gbufq.y));\
    float s2q = tx.w - luminance_rec2020(tx.rgb)*luminance_rec2020(tx.rgb);\
    float s2p = Lp.w - m1*m1;\
    float w = edge(\
        vec2(i,j), max(s2p,s2q), \
        Lp.rgb, Lq,\
        normal, nq,\
        depth, gbufq.x);\
    res += w*tx;\
    w_sum += w;\
    } while(false)
  { int j=-2; for(int i=-1;i<=1;i++) FILTER; }
  { int j=-1; for(int i=-2;i<=2;i++) FILTER; }
  { int j= 0; for(int i=-2;i<=2;i++) if(i!=0) FILTER; }
  { int j= 1; for(int i=-2;i<=2;i++) FILTER; }
  { int j= 2; for(int i=-1;i<=1;i++) FILTER; }
#undef FILTER
  res /= w_sum;

  // sort image to write positions so we can iterate the filter
  ipos = mix(ipos / 2, imageSize(img_out)-1-ipos/2, equal(ipos & 1, ivec2(0)));

  // DEBUG vis relative std dev estimate for first level
  // res.rgb = clamp(vec3(sqrt(max(0, Lp.w - m1*m1))/m1), 0, 65000.0);

  imageStore(img_out,      ipos, res);
  imageStore(img_gbuf_out, ipos, gbuf);
}

